{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5d0d001",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab4287b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import List, Dict\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3bac14",
   "metadata": {},
   "source": [
    "# Acesso a API\n",
    "- Identificação e download dos arquivos ZIP selecionados \n",
    "- Extração dos ZIPs \n",
    "- Identificação dos arquivos com Despesas com Eventos/Sinistros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a00583",
   "metadata": {},
   "source": [
    "### Identificação e download dos arquivos ZIP selecionados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c405792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_years(URL: str, session: requests.Session) -> List[str]:\n",
    "    \"\"\"\n",
    "    Obtém a lista de anos disponíveis na página base.\n",
    "    \"\"\"\n",
    "    resp = session.get(URL, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "    padrao_ano = re.compile(r\"^(20\\d{2})/$\")\n",
    "\n",
    "    anos = []\n",
    "    for link in soup.find_all(\"a\"):\n",
    "        href = link.get(\"href\", \"\")\n",
    "        match = padrao_ano.match(href)\n",
    "        if match:\n",
    "            anos.append(match.group(1))\n",
    "\n",
    "    if not anos:\n",
    "        raise RuntimeError(\"Nenhum ano encontrado no diretório base.\")\n",
    "\n",
    "    return anos\n",
    "\n",
    "def get_trimesters(URL: str, ano: str, session: requests.Session) -> List[Dict[str, any]]:\n",
    "    url_ano = urljoin(URL, f\"{ano}/\")\n",
    "    print(f\"\\nProcessando ano {ano}...\")\n",
    "    resp_ano = session.get(url_ano, timeout=30)\n",
    "    if resp_ano.status_code != 200:\n",
    "        print(f\"Falha ao acessar {url_ano}\")\n",
    "        return []\n",
    "\n",
    "    soup_ano = BeautifulSoup(resp_ano.text, \"html.parser\")\n",
    "    arquivos = []\n",
    "\n",
    "    # Para cada ZIP\n",
    "    for link in soup_ano.find_all(\"a\"):\n",
    "        href = link.get(\"href\", \"\")\n",
    "            \n",
    "        if not href.lower().endswith(\".zip\"):\n",
    "                continue\n",
    "            \n",
    "        trimestre = extract_trimesters(href)\n",
    "\n",
    "        arquivos.append({\n",
    "            \"ano\": ano,\n",
    "            \"trimestre\": trimestre,\n",
    "            \"nome\": href,\n",
    "            \"url\": urljoin(url_ano, href)\n",
    "        })\n",
    "\n",
    "    if not arquivos:\n",
    "        print(f\"Nenhum ZIP encontrado para {ano}\")\n",
    "        return []\n",
    "\n",
    "    # Selecionar os 3 ultimos semestres\n",
    "    arquivos.sort(key=lambda x: x[\"trimestre\"], reverse=True)\n",
    "    return arquivos[:3]\n",
    "\n",
    "def extract_trimesters(nome_arquivo: str) -> int:\n",
    "    \"\"\"\n",
    "    Extrai os trimestre dos nomes de arquivos ZIP.\n",
    "    \"\"\"\n",
    "    nome = nome_arquivo.lower()\n",
    "\n",
    "    # Encontrar trimestre no nome\n",
    "    padroes_trimestre = [\n",
    "        r'([1-4])\\s*t',              # 1T, 1t\n",
    "        r'([1-4])\\s*trim',           # 1trim\n",
    "        r'([1-4])\\s*trimestre',      # 1trimestre\n",
    "        r'([1-4])\\s*[-_ ]\\s*trim',   # 1-trim\n",
    "    ]\n",
    "\n",
    "    trimestre = None\n",
    "    for padrao in padroes_trimestre:\n",
    "        match = re.search(padrao, nome)\n",
    "        if match:\n",
    "            trimestre = int(match.group(1))\n",
    "            break\n",
    "\n",
    "    if trimestre is None:\n",
    "        raise ValueError(f\"Trimestre não encontrado no nome do arquivo: {nome_arquivo}\")\n",
    "\n",
    "    return trimestre\n",
    "\n",
    "def download_trimesters(pasta_destino, session, ano, trimestres):\n",
    "    pasta_ano = os.path.join(pasta_destino, ano)\n",
    "    os.makedirs(pasta_ano, exist_ok=True)\n",
    "\n",
    "    for arq in trimestres:\n",
    "        destino = os.path.join(pasta_ano, arq[\"nome\"])\n",
    "\n",
    "        if os.path.exists(destino):\n",
    "            print(f\"Já existe: {arq['nome']}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Baixando: {arq['nome']}\")\n",
    "\n",
    "        with session.get(arq[\"url\"], stream=True, timeout=60) as r:\n",
    "            r.raise_for_status()\n",
    "            with open(destino, \"wb\") as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "\n",
    "def baixar_ultimos_3_trimestres(pasta_destino: str):\n",
    "    URL = \"https://dadosabertos.ans.gov.br/FTP/PDA/demonstracoes_contabeis/\"\n",
    "    os.makedirs(pasta_destino, exist_ok=True)\n",
    "\n",
    "    session = requests.Session()\n",
    "    session.headers.update({\"User-Agent\": \"ANS-Crawler/1.0\"})\n",
    "\n",
    "    # 1- Acessar lista de anos\n",
    "    anos = get_years(URL, session)\n",
    "\n",
    "    # 2- Para cada ano obter trimestres\n",
    "    for ano in anos:\n",
    "        trimestres = get_trimesters(URL, ano, session)\n",
    "\n",
    "        # 3- Baixar os trimestres selecionados\n",
    "        download_trimesters(pasta_destino, session, ano, trimestres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71480e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "baixar_ultimos_3_trimestres(pasta_destino= \"downloads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7f0047",
   "metadata": {},
   "source": [
    "### Extração dos ZIPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "32195148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_zip(caminho_zip, pasta_destino):\n",
    "    \"\"\" \n",
    "    Extrai um aquivo ZIP para uma pasta destino\n",
    "    \"\"\"\n",
    "    pasta_destino = Path(pasta_destino)\n",
    "    pasta_destino.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with zipfile.ZipFile(caminho_zip, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(pasta_destino)\n",
    "\n",
    "def extrair_todos_os_zips(pasta_origem, pasta_destino):\n",
    "    \"\"\" \n",
    "    Extrai todos os ZIPs de uma pasta e coloca os arq extraidos para a pasta detino\n",
    "    \"\"\"\n",
    "    pasta_origem = Path(pasta_origem)\n",
    "    pasta_destino = Path(pasta_destino)\n",
    "\n",
    "    print(f\"Extraindo pasta {pasta_origem}\")\n",
    "\n",
    "    pasta_destino.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for zip_path in pasta_origem.rglob(\"*.zip\"):\n",
    "        with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(pasta_destino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "811328e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraindo pasta downloads\\2007\n",
      "Extraindo pasta downloads\\2008\n",
      "Extraindo pasta downloads\\2009\n",
      "Extraindo pasta downloads\\2010\n",
      "Extraindo pasta downloads\\2011\n",
      "Extraindo pasta downloads\\2012\n",
      "Extraindo pasta downloads\\2013\n",
      "Extraindo pasta downloads\\2014\n",
      "Extraindo pasta downloads\\2015\n",
      "Extraindo pasta downloads\\2016\n",
      "Extraindo pasta downloads\\2017\n",
      "Extraindo pasta downloads\\2018\n",
      "Extraindo pasta downloads\\2019\n",
      "Extraindo pasta downloads\\2020\n",
      "Extraindo pasta downloads\\2021\n",
      "Extraindo pasta downloads\\2022\n",
      "Extraindo pasta downloads\\2023\n",
      "Extraindo pasta downloads\\2024\n",
      "Extraindo pasta downloads\\2025\n"
     ]
    }
   ],
   "source": [
    "for i in range(2007, 2026):\n",
    "    extrair_todos_os_zips(f\"downloads/{i}/\", f\"downloads/{i}/extraido\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
