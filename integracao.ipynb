{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5d0d001",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab4287b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import List, Dict\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3bac14",
   "metadata": {},
   "source": [
    "# Acesso a API\n",
    "- Identificação e download dos arquivos ZIP selecionados \n",
    "- Extração dos ZIPs \n",
    "- Identificação dos arquivos com Despesas com Eventos/Sinistros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a00583",
   "metadata": {},
   "source": [
    "### Identificação e download dos arquivos ZIP selecionados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c405792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_years_from_home_page(URL: str, session: requests.Session) -> List[str]:\n",
    "    \"\"\"\n",
    "    Obtém a lista de anos disponíveis na página base.\n",
    "    \"\"\"\n",
    "    resp = session.get(URL, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "    padrao_ano = re.compile(r\"^(20\\d{2})/$\")\n",
    "\n",
    "    anos = []\n",
    "    for link in soup.find_all(\"a\"):\n",
    "        href = link.get(\"href\", \"\")\n",
    "        match = padrao_ano.match(href)\n",
    "        if match:\n",
    "            anos.append(match.group(1))\n",
    "\n",
    "    if not anos:\n",
    "        raise RuntimeError(\"Nenhum ano encontrado no diretório base.\")\n",
    "\n",
    "    return anos\n",
    "\n",
    "def get_trimesters_from_page(URL: str, ano: str, session: requests.Session) -> List[Dict[str, any]]:\n",
    "    \"\"\"\n",
    "    Obtém os 3 ultimos trimestres disponível para o ano fornecido.\n",
    "    \"\"\"\n",
    "    url_ano = urljoin(URL, f\"{ano}/\")\n",
    "    print(f\"\\nProcessando ano {ano}...\")\n",
    "    resp_ano = session.get(url_ano, timeout=30)\n",
    "    if resp_ano.status_code != 200:\n",
    "        print(f\"Falha ao acessar {url_ano}\")\n",
    "        return []\n",
    "\n",
    "    soup_ano = BeautifulSoup(resp_ano.text, \"html.parser\")\n",
    "    arquivos = []\n",
    "\n",
    "    # Para cada ZIP\n",
    "    for link in soup_ano.find_all(\"a\"):\n",
    "        href = link.get(\"href\", \"\")\n",
    "            \n",
    "        if not href.lower().endswith(\".zip\"):\n",
    "                continue\n",
    "            \n",
    "        trimestre = extrair_trimestres(href)\n",
    "\n",
    "        arquivos.append({\n",
    "            \"ano\": ano,\n",
    "            \"trimestre\": trimestre,\n",
    "            \"nome\": href,\n",
    "            \"url\": urljoin(url_ano, href)\n",
    "        })\n",
    "\n",
    "    if not arquivos:\n",
    "        print(f\"Nenhum ZIP encontrado para {ano}\")\n",
    "        return []\n",
    "\n",
    "    # Selecionar os 3 ultimos semestres\n",
    "    arquivos.sort(key=lambda x: x[\"trimestre\"], reverse=True)\n",
    "    return arquivos[:3]\n",
    "\n",
    "def extrair_trimestres(nome_arquivo: str) -> str:\n",
    "    \"\"\"\n",
    "    Extrai os trimestre dos nomes de arquivos ZIP.\n",
    "    \"\"\"\n",
    "    nome = nome_arquivo.lower()\n",
    "\n",
    "    # Encontrar trimestre no nome\n",
    "    padroes_trimestre = [\n",
    "        r'([1-4])\\s*t',              # 1T, 1t\n",
    "        r'([1-4])\\s*trim',           # 1trim\n",
    "        r'([1-4])\\s*trimestre',      # 1trimestre\n",
    "        r'([1-4])\\s*[-_ ]\\s*trim',   # 1-trim\n",
    "    ]\n",
    "\n",
    "    trimestre = None\n",
    "    for padrao in padroes_trimestre:\n",
    "        match = re.search(padrao, nome)\n",
    "        if match:\n",
    "            trimestre = int(match.group(1))\n",
    "            break\n",
    "\n",
    "    if trimestre is None:\n",
    "        raise ValueError(f\"Trimestre não encontrado no nome do arquivo: {nome_arquivo}\")\n",
    "\n",
    "    return trimestre\n",
    "\n",
    "def download_trimesters(pasta_destino: str, session: requests.Session, ano: str, trimestres: List[Dict[str, any]]) -> None:\n",
    "    pasta_ano = os.path.join(pasta_destino, ano)\n",
    "    os.makedirs(pasta_ano, exist_ok=True)\n",
    "\n",
    "    for arq in trimestres:\n",
    "        destino = os.path.join(pasta_ano, arq[\"nome\"])\n",
    "\n",
    "        if os.path.exists(destino):\n",
    "            print(f\"Já existe: {arq['nome']}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Baixando: {arq['nome']}\")\n",
    "\n",
    "        with session.get(arq[\"url\"], stream=True, timeout=60) as r:\n",
    "            r.raise_for_status()\n",
    "            with open(destino, \"wb\") as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "\n",
    "def baixar_ultimos_3_trimestres(pasta_destino: str):\n",
    "    URL = \"https://dadosabertos.ans.gov.br/FTP/PDA/demonstracoes_contabeis/\"\n",
    "    os.makedirs(pasta_destino, exist_ok=True)\n",
    "\n",
    "    session = requests.Session()\n",
    "    session.headers.update({\"User-Agent\": \"ANS-Crawler/1.0\"})\n",
    "\n",
    "    # 1- Acessar lista de anos\n",
    "    anos = get_years_from_home_page(URL, session)\n",
    "\n",
    "    # 2- Para cada ano obter trimestres\n",
    "    for ano in anos:\n",
    "        trimestres = get_trimesters_from_page(URL, ano, session)\n",
    "\n",
    "        # 3- Baixar os trimestres selecionados\n",
    "        download_trimesters(pasta_destino, session, ano, trimestres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d71480e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando ano 2007...\n",
      "Baixando: 2007_4_trimestre.zip\n",
      "Baixando: 2007_3_trimestre.zip\n",
      "Baixando: 2007_2_trimestre.zip\n",
      "\n",
      "Processando ano 2008...\n",
      "Baixando: 2008_4_trimestre.zip\n",
      "Baixando: 2008_3_trimestre.zip\n",
      "Baixando: 2008_2_trimestre.zip\n",
      "\n",
      "Processando ano 2009...\n",
      "Baixando: 2009_4_trimestre.zip\n",
      "Baixando: 2009_3_trimestre.zip\n",
      "Baixando: 2009_2_trimestre.zip\n",
      "\n",
      "Processando ano 2010...\n",
      "Baixando: 2010_4_trimestre.zip\n",
      "Baixando: 2010_3_trimestre.zip\n",
      "Baixando: 2010_2_trimestre.zip\n",
      "\n",
      "Processando ano 2011...\n",
      "Baixando: 20120614_2011_4_trimestre.zip\n",
      "Baixando: 20120614_2011_3_trimestre.zip\n",
      "Baixando: 20120614_2011_2_trimestre.zip\n",
      "\n",
      "Processando ano 2012...\n",
      "Baixando: 20130416_4T2012.zip\n",
      "Baixando: 20130416_3T2012.zip\n",
      "Baixando: 20130416_2T2012.zip\n",
      "\n",
      "Processando ano 2013...\n",
      "Baixando: 2013-4t.zip\n",
      "Baixando: 2013-3t.zip\n",
      "Baixando: 2013-2t.zip\n",
      "\n",
      "Processando ano 2014...\n",
      "Baixando: 4T2014.zip\n",
      "Baixando: 3T2014.zip\n",
      "Baixando: 2T2014.zip\n",
      "\n",
      "Processando ano 2015...\n",
      "Baixando: 4T2015.zip\n",
      "Baixando: 3T2015.zip\n",
      "Baixando: 2T2015.zip\n",
      "\n",
      "Processando ano 2016...\n",
      "Baixando: 4T2016.zip\n",
      "Baixando: 3T2016.zip\n",
      "Baixando: 2T2016.zip\n",
      "\n",
      "Processando ano 2017...\n",
      "Baixando: 4T2017.zip\n",
      "Baixando: 3-Trimestre.zip\n",
      "Baixando: 2T2017.zip\n",
      "\n",
      "Processando ano 2018...\n",
      "Baixando: 4T2018.zip\n",
      "Baixando: 3T2018.zip\n",
      "Baixando: 2T2018.zip\n",
      "\n",
      "Processando ano 2019...\n",
      "Baixando: 4T2019.zip\n",
      "Baixando: 3T2019.zip\n",
      "Baixando: 2T2019.zip\n",
      "\n",
      "Processando ano 2020...\n",
      "Baixando: 4T2020.zip\n",
      "Baixando: 3T2020.zip\n",
      "Baixando: 2T2020.zip\n",
      "\n",
      "Processando ano 2021...\n",
      "Baixando: 4T2021.zip\n",
      "Baixando: 3T2021.zip\n",
      "Baixando: 2T2021.zip\n",
      "\n",
      "Processando ano 2022...\n",
      "Baixando: 4T2022.zip\n",
      "Baixando: 3T2022.zip\n",
      "Baixando: 2T2022.zip\n",
      "\n",
      "Processando ano 2023...\n",
      "Baixando: 4T2023.zip\n",
      "Baixando: 3T2023.zip\n",
      "Baixando: 2T2023.zip\n",
      "\n",
      "Processando ano 2024...\n",
      "Baixando: 4T2024.zip\n",
      "Baixando: 3T2024.zip\n",
      "Baixando: 2T2024.zip\n",
      "\n",
      "Processando ano 2025...\n",
      "Baixando: 3T2025.zip\n",
      "Baixando: 2T2025.zip\n",
      "Baixando: 1T2025.zip\n"
     ]
    }
   ],
   "source": [
    "# baixar_ultimos_3_trimestres(pasta_destino= \"downloads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7f0047",
   "metadata": {},
   "source": [
    "### Extração dos ZIPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32195148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_zip(caminho_zip: str, pasta_destino: str):\n",
    "    \"\"\" \n",
    "    Extrai um aquivo ZIP para uma pasta destino\n",
    "    \"\"\"\n",
    "    pasta_destino = Path(pasta_destino)\n",
    "    pasta_destino.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with zipfile.ZipFile(caminho_zip, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(pasta_destino)\n",
    "\n",
    "def extrair_todos_os_zips_da_pasta(pasta_origem: str, pasta_destino: str):\n",
    "    \"\"\" \n",
    "    Extrai todos os ZIPs de uma pasta e coloca os arq extraidos para a pasta detino\n",
    "    \"\"\"\n",
    "    pasta_origem = Path(pasta_origem)\n",
    "    pasta_destino = Path(pasta_destino)\n",
    "\n",
    "    print(f\"Extraindo pasta {pasta_origem}\")\n",
    "\n",
    "    pasta_destino.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for zip_path in pasta_origem.rglob(\"*.zip\"):\n",
    "        with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(pasta_destino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "811328e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(2007, 2026):\n",
    "#     extrair_todos_os_zips_da_pasta(f\"downloads/{i}/\", f\"downloads/{i}/extraido\")\n",
    "# \n",
    "# extrair_todos_os_zips_da_pasta(f\"downloads/2025/\", f\"downloads/2025/extraido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1e0ba3",
   "metadata": {},
   "source": [
    "### Identificação dos arquivos com \"Despesas com Eventos/Sinistros\" \n",
    "- Incrementalmente\n",
    "- FILTRO: Textos que começam com ‘despesas com eventos / sinistros’, independentemente da quantidade de espaços entre as palavras, e podendo ter qualquer texto depois.\n",
    "- Para os anos de 2010, 2011, 2012, 2013, 2014, 2015, 2016 não foram encontradas ocorrencias de \"Despesas com Eventos/Sinistros\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bd30969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_contem(csv_path: str, coluna: str, texto_procurado: str, chunksize: int =100_000) -> bool:\n",
    "    \"\"\"\n",
    "    Verifica se o csv contem o texto na coluna especificada\n",
    "    \"\"\"\n",
    "\n",
    "    encontrou = False\n",
    "\n",
    "    for chunk in pd.read_csv(\n",
    "    csv_path,\n",
    "    sep=';',\n",
    "    dtype=str,\n",
    "    chunksize=chunksize,\n",
    "    encoding='latin1'\n",
    "    ):\n",
    "        if chunk[coluna].str.contains(texto_procurado, case=False, na=False).any():\n",
    "            encontrou = True\n",
    "            break\n",
    "    \n",
    "    return encontrou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62b87e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2007: [True, True, True], 2008: [True, True, True], 2009: [True, True, True], 2010: [False, False, False], 2011: [False, False, False], 2012: [False, False, False], 2013: [False, False, False], 2014: [False, False, False], 2015: [False, False, False], 2016: [False, False, False], 2017: [True, True, True], 2018: [True, True, True], 2019: [True, True, True], 2020: [True, True, True], 2021: [True, True, True], 2022: [True, True, True], 2023: [True, True, True], 2024: [True, True, True], 2025: [True, True, True]}\n"
     ]
    }
   ],
   "source": [
    "dict = {}\n",
    "for i in range(2007, 2026):\n",
    "        pasta_origem = Path(f\"downloads/{i}/extraido/\")\n",
    "        dict[i] = []\n",
    "        for csv_path in pasta_origem.glob(\"*.csv\"):\n",
    "                tem = csv_contem(csv_path, 'DESCRICAO', r'^despesas\\s+com\\s+eventos\\s*/\\s*sinistros.*')\n",
    "                dict[i].append(tem)\n",
    "\n",
    "print(dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
