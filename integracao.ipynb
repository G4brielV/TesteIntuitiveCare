{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5d0d001",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab4287b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import List, Dict\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3bac14",
   "metadata": {},
   "source": [
    "# Acesso a API\n",
    "- Identificação e download dos arquivos ZIP selecionados \n",
    "- Extração dos ZIPs \n",
    "- Identificação dos arquivos com Despesas com Eventos/Sinistros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a00583",
   "metadata": {},
   "source": [
    "### Identificação e download dos arquivos ZIP selecionados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c405792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_years_from_home_page(URL: str, session: requests.Session) -> List[str]:\n",
    "    \"\"\"\n",
    "    Obtém a lista de anos disponíveis na página base.\n",
    "    \"\"\"\n",
    "    resp = session.get(URL, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "    padrao_ano = re.compile(r\"^(20\\d{2})/$\")\n",
    "\n",
    "    anos = []\n",
    "    for link in soup.find_all(\"a\"):\n",
    "        href = link.get(\"href\", \"\")\n",
    "        match = padrao_ano.match(href)\n",
    "        if match:\n",
    "            anos.append(match.group(1))\n",
    "\n",
    "    if not anos:\n",
    "        raise RuntimeError(\"Nenhum ano encontrado no diretório base.\")\n",
    "\n",
    "    return anos\n",
    "\n",
    "def get_trimesters_from_page(URL: str, ano: str, session: requests.Session) -> List[Dict[str, any]]:\n",
    "    \"\"\"\n",
    "    Obtém os 3 ultimos trimestres disponível para o ano fornecido.\n",
    "    \"\"\"\n",
    "    url_ano = urljoin(URL, f\"{ano}/\")\n",
    "    print(f\"\\nProcessando ano {ano}...\")\n",
    "    resp_ano = session.get(url_ano, timeout=30)\n",
    "    if resp_ano.status_code != 200:\n",
    "        print(f\"Falha ao acessar {url_ano}\")\n",
    "        return []\n",
    "\n",
    "    soup_ano = BeautifulSoup(resp_ano.text, \"html.parser\")\n",
    "    arquivos = []\n",
    "\n",
    "    # Para cada ZIP\n",
    "    for link in soup_ano.find_all(\"a\"):\n",
    "        href = link.get(\"href\", \"\")\n",
    "            \n",
    "        if not href.lower().endswith(\".zip\"):\n",
    "                continue\n",
    "            \n",
    "        trimestre = extrair_trimestres(href)\n",
    "\n",
    "        arquivos.append({\n",
    "            \"ano\": ano,\n",
    "            \"trimestre\": trimestre,\n",
    "            \"nome\": href,\n",
    "            \"url\": urljoin(url_ano, href)\n",
    "        })\n",
    "\n",
    "    if not arquivos:\n",
    "        print(f\"Nenhum ZIP encontrado para {ano}\")\n",
    "        return []\n",
    "\n",
    "    # Selecionar os 3 ultimos semestres\n",
    "    arquivos.sort(key=lambda x: x[\"trimestre\"], reverse=True)\n",
    "    return arquivos[:3]\n",
    "\n",
    "def extrair_trimestres(nome_arquivo: str) -> str:\n",
    "    \"\"\"\n",
    "    Extrai os trimestre dos nomes de arquivos ZIP.\n",
    "    \"\"\"\n",
    "    nome = nome_arquivo.lower()\n",
    "\n",
    "    # Encontrar trimestre no nome\n",
    "    padroes_trimestre = [\n",
    "        r'([1-4])\\s*t',              # 1T, 1t\n",
    "        r'([1-4])\\s*trim',           # 1trim\n",
    "        r'([1-4])\\s*trimestre',      # 1trimestre\n",
    "        r'([1-4])\\s*[-_ ]\\s*trim',   # 1-trim\n",
    "    ]\n",
    "\n",
    "    trimestre = None\n",
    "    for padrao in padroes_trimestre:\n",
    "        match = re.search(padrao, nome)\n",
    "        if match:\n",
    "            trimestre = int(match.group(1))\n",
    "            break\n",
    "\n",
    "    if trimestre is None:\n",
    "        raise ValueError(f\"Trimestre não encontrado no nome do arquivo: {nome_arquivo}\")\n",
    "\n",
    "    return trimestre\n",
    "\n",
    "def download_trimesters(pasta_destino: str, session: requests.Session, ano: str, trimestres: List[Dict[str, any]]) -> None:\n",
    "    pasta_ano = os.path.join(pasta_destino, ano)\n",
    "    os.makedirs(pasta_ano, exist_ok=True)\n",
    "\n",
    "    for arq in trimestres:\n",
    "        destino = os.path.join(pasta_ano, arq[\"nome\"])\n",
    "\n",
    "        if os.path.exists(destino):\n",
    "            print(f\"Já existe: {arq['nome']}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Baixando: {arq['nome']}\")\n",
    "\n",
    "        with session.get(arq[\"url\"], stream=True, timeout=60) as r:\n",
    "            r.raise_for_status()\n",
    "            with open(destino, \"wb\") as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "\n",
    "def baixar_ultimos_3_trimestres(pasta_destino: str):\n",
    "    URL = \"https://dadosabertos.ans.gov.br/FTP/PDA/demonstracoes_contabeis/\"\n",
    "    os.makedirs(pasta_destino, exist_ok=True)\n",
    "\n",
    "    session = requests.Session()\n",
    "    session.headers.update({\"User-Agent\": \"ANS-Crawler/1.0\"})\n",
    "\n",
    "    # 1- Acessar lista de anos\n",
    "    anos = get_years_from_home_page(URL, session)\n",
    "\n",
    "    # 2- Para cada ano obter trimestres\n",
    "    for ano in anos:\n",
    "        trimestres = get_trimesters_from_page(URL, ano, session)\n",
    "\n",
    "        # 3- Baixar os trimestres selecionados\n",
    "        download_trimesters(pasta_destino, session, ano, trimestres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71480e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "baixar_ultimos_3_trimestres(pasta_destino= \"downloads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7f0047",
   "metadata": {},
   "source": [
    "### Extração dos ZIPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32195148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrair_zip(caminho_zip: str, pasta_destino: str):\n",
    "    \"\"\" \n",
    "    Extrai um aquivo ZIP para uma pasta destino\n",
    "    \"\"\"\n",
    "    pasta_destino = Path(pasta_destino)\n",
    "    pasta_destino.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with zipfile.ZipFile(caminho_zip, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(pasta_destino)\n",
    "\n",
    "def extrair_todos_os_zips_da_pasta(pasta_origem: str, pasta_destino: str):\n",
    "    \"\"\" \n",
    "    Extrai todos os ZIPs de uma pasta e coloca os arq extraidos para a pasta detino\n",
    "    \"\"\"\n",
    "    pasta_origem = Path(pasta_origem)\n",
    "    pasta_destino = Path(pasta_destino)\n",
    "\n",
    "    print(f\"Extraindo pasta {pasta_origem}\")\n",
    "\n",
    "    pasta_destino.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for zip_path in pasta_origem.rglob(\"*.zip\"):\n",
    "        with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(pasta_destino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811328e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2007, 2026):\n",
    "    extrair_todos_os_zips_da_pasta(f\"downloads/{i}/\", f\"downloads/{i}/extraido\")\n",
    "\n",
    "# extrair_todos_os_zips_da_pasta(f\"downloads/2025/\", f\"downloads/2025/extraido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1e0ba3",
   "metadata": {},
   "source": [
    "### Identificação dos arquivos com \"Despesas com Eventos/Sinistros\" \n",
    "- Incrementalmente - Economiza memória e caso a ocorrência desejada seja encontrada nos primeiros chunks, o processamento é interrompido.\n",
    "- FILTRO: Textos que começam com ‘despesas com eventos / sinistros’, independentemente da quantidade de espaços entre as palavras, e podendo ter qualquer texto depois.\n",
    "- Para os anos de 2010, 2011, 2012, 2013, 2014, 2015, 2016 não foram encontradas ocorrencias de \"Despesas com Eventos/Sinistros\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bd30969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_contem(csv_path: str, coluna: str, texto_procurado: str, chunksize: int =100_000) -> bool:\n",
    "    \"\"\"\n",
    "    Verifica se o csv contem o texto na coluna especificada\n",
    "    \"\"\"\n",
    "\n",
    "    encontrou = False\n",
    "\n",
    "    for chunk in pd.read_csv(\n",
    "    csv_path,\n",
    "    sep=';',\n",
    "    dtype=str,\n",
    "    chunksize=chunksize,\n",
    "    encoding='latin1'\n",
    "    ):\n",
    "        if chunk[coluna].str.contains(texto_procurado, case=False, na=False).any():\n",
    "            encontrou = True\n",
    "            break\n",
    "    \n",
    "    return encontrou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62b87e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2007: [True, True, True], 2008: [True, True, True], 2009: [True, True, True], 2010: [False, False, False], 2011: [False, False, False], 2012: [False, False, False], 2013: [False, False, False], 2014: [False, False, False], 2015: [False, False, False], 2016: [False, False, False], 2017: [True, True, True], 2018: [True, True, True], 2019: [True, True, True], 2020: [True, True, True], 2021: [True, True, True], 2022: [True, True, True], 2023: [True, True, True], 2024: [True, True, True], 2025: [True, True, True]}\n"
     ]
    }
   ],
   "source": [
    "dict = {}\n",
    "for i in range(2007, 2026):\n",
    "        pasta_origem = Path(f\"downloads/{i}/extraido/\")\n",
    "        dict[i] = []\n",
    "        for csv_path in pasta_origem.glob(\"*.csv\"):\n",
    "                tem = csv_contem(csv_path, 'DESCRICAO', r'^despesas\\s+com\\s+eventos\\s*/\\s*sinistros.*')\n",
    "                dict[i].append(tem)\n",
    "\n",
    "print(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601d65d4",
   "metadata": {},
   "source": [
    "### Consolidação CSV - 3 Trimestres\n",
    "- CNPJs duplicados com razões sociais diferentes -> NÃO EXISTE\n",
    "- Tem cnpj com razao duplicado apenas no Merge com o relatório, pois existem contas contabeis diferentes, que não foram trazidas para o df final\n",
    "- ValorDespesas ->\n",
    "    - Tem a coluna VL_SALDO_INICIAL: If (df['VL_SALDO_FINAL'] > df['VL_SALDO_INICIAL']) ? 'VL_SALDO_FINAL' - 'VL_SALDO_INICIAL' : 0\n",
    "    - Não tem coluna VL_SALDO_INICIAL: If (df['VL_SALDO_FINAL'] > 0) ? 'VL_SALDO_FINAL' : 0\n",
    "- Data formatada com o pandas = CORRIGIDO\n",
    "\n",
    "- Merge/Join com left, havendo registros que tem REG_ANS, mas não tem REGISTRO_OPERADORA no relatório\n",
    "- PQ O LEFT?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dc0a40",
   "metadata": {},
   "source": [
    "#### Prova que no relatorio, não existe CNPJ com mais de uma Razao Social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f667a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = pd.read_csv(f\"/Relatorio_cadop.csv\", sep=';', dtype=str, encoding='latin1', usecols=[\"REGISTRO_OPERADORA\", \"CNPJ\", \"Razao_Social\"])\n",
    "# eh_1_para_1 = (b.groupby('CNPJ')['Razao_Social'].nunique() == 1).all()\n",
    "# print(eh_1_para_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d886fe",
   "metadata": {},
   "source": [
    "#### Consolidação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e1c81e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baixar_relatorio_ans(pasta_destino: Path=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Baixa o relatório de operadoras de planos de saúde ativas na ANS e exporta como df\n",
    "    \"\"\"\n",
    "    url = \"https://dadosabertos.ans.gov.br/FTP/PDA/operadoras_de_plano_de_saude_ativas/Relatorio_cadop.csv\"\n",
    "    nome_arquivo = \"Relatorio_cadop.csv\"\n",
    "\n",
    "    # Diretório do arquivo .py que está rodando\n",
    "    base_dir = os.getcwd()\n",
    "\n",
    "    # Se não passar pasta_destino, usa o diretório do script\n",
    "    if pasta_destino is None:\n",
    "        pasta_destino = base_dir\n",
    "    else:\n",
    "        os.makedirs(pasta_destino, exist_ok=True)\n",
    "\n",
    "    caminho_arquivo = os.path.join(pasta_destino, nome_arquivo)\n",
    "\n",
    "    # Verifica se o arquivo não existe \n",
    "    if os.path.exists(caminho_arquivo) == False:\n",
    "        print(\"BAIXOU RELATORIO\")\n",
    "        with requests.Session() as session:\n",
    "            response = session.get(url, timeout=60)\n",
    "            response.raise_for_status()  \n",
    "        with open(caminho_arquivo, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "    return pd.read_csv(f\"{pasta_destino}/Relatorio_cadop.csv\", sep=';', dtype=str, encoding='latin1', usecols=[\"REGISTRO_OPERADORA\", \"CNPJ\", \"Razao_Social\"])\n",
    "def processar_csvs(pasta_origem: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Processa todos os CSVs da pasta de um ano e retorna um DataFrame normalizado com: REG_ANS | Ano | Trimestre | ValorDespesas\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    # Para cada CSV na pasta\n",
    "    for csv_path in pasta_origem.glob(\"*.csv\"):\n",
    "        df = pd.read_csv(\n",
    "            csv_path,\n",
    "            sep=';',\n",
    "            dtype=str,\n",
    "            encoding='latin1'\n",
    "        )\n",
    "        # Normalização\n",
    "        df.columns = [c.upper().strip() for c in df.columns]\n",
    "        df['DESCRICAO'] = df['DESCRICAO'].str.lower().str.strip()\n",
    "        df['DATA'] = pd.to_datetime(df['DATA'], errors='coerce') # -> Consistencia para as datas\n",
    "\n",
    "        # Valor numérico STR -> FLOAT\n",
    "        df['VL_SALDO_FINAL'] = (\n",
    "            df['VL_SALDO_FINAL']\n",
    "            .str.replace('.', '', regex=False)\n",
    "            .str.replace(',', '.', regex=False)\n",
    "            .astype(float)\n",
    "        )\n",
    "\n",
    "\n",
    "        if 'VL_SALDO_INICIAL' in df.columns:\n",
    "\n",
    "            df['VL_SALDO_INICIAL'] = (\n",
    "            df['VL_SALDO_INICIAL']\n",
    "            .str.replace('.', '', regex=False)\n",
    "            .str.replace(',', '.', regex=False)\n",
    "            .astype(float)\n",
    "            )\n",
    "\n",
    "            df['ValorDespesas'] = np.where(\n",
    "                df['VL_SALDO_FINAL'] > df['VL_SALDO_INICIAL'],\n",
    "                df['VL_SALDO_FINAL'] - df['VL_SALDO_INICIAL'],\n",
    "                0.0\n",
    "            )\n",
    "        else:\n",
    "            df['ValorDespesas'] = np.where(\n",
    "                df['VL_SALDO_FINAL'] > 0,\n",
    "                df['VL_SALDO_FINAL'],\n",
    "                0.0\n",
    "            )\n",
    "\n",
    "            \n",
    "        df_normalizado = df[['REG_ANS', 'ValorDespesas']].copy()\n",
    "        df_normalizado['Ano'] = df['DATA'].dt.year\n",
    "        df_normalizado['Trimestre'] = df['DATA'].dt.quarter\n",
    "\n",
    "        dfs.append(df_normalizado)\n",
    "\n",
    "    if not dfs:\n",
    "        return pd.DataFrame(\n",
    "            columns=['REG_ANS', 'Ano', 'Trimestre', 'ValorDespesas']\n",
    "        )\n",
    "\n",
    "    df_ano = pd.concat(dfs, ignore_index=True)\n",
    "    return df_ano\n",
    "def consolidar_despesas(pasta_origem:str, pasta_destino:str=''):\n",
    "    \"\"\"\n",
    "    Baixa o relatório da ANS consolida os CSVs de uma pasta e salva em uma pasta destino o csv e o zip com os dados consolidados\n",
    "    \"\"\"\n",
    "    pasta_origem = Path(pasta_origem)\n",
    "    pasta_destino = Path(pasta_destino)\n",
    "    pasta_destino.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    relatorio = baixar_relatorio_ans()\n",
    "    df_ano = processar_csvs(pasta_origem)\n",
    "    df_final = df_ano.merge(\n",
    "    relatorio,\n",
    "    left_on=\"REG_ANS\",\n",
    "    right_on=\"REGISTRO_OPERADORA\",\n",
    "    how=\"left\"   \n",
    "    ).drop(columns=[\"REGISTRO_OPERADORA\", \"REG_ANS\"])\n",
    "\n",
    "    df_final.to_csv(pasta_destino / \"consolidado_despesas.csv\", encoding='iso-8859-1', index=False)\n",
    "\n",
    "    with zipfile.ZipFile(pasta_destino / \"consolidado_despesas.zip\", \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
    "        zipf.write(pasta_destino / \"consolidado_despesas.csv\", arcname=\"consolidado_despesas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a42e7391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consolidar_despesas(f\"downloads/2007/extraido\", f\"downloads/2007/extraido/consolidado\")\n",
    "for i in range(2007, 2026):\n",
    "    consolidar_despesas(f\"downloads/{i}/extraido\", f\"downloads/{i}/extraido/consolidado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde1385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REG_ANS</th>\n",
       "      <th>ValorDespesas</th>\n",
       "      <th>Ano</th>\n",
       "      <th>Trimestre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>316458</td>\n",
       "      <td>1070.00</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>316458</td>\n",
       "      <td>1070.00</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316458</td>\n",
       "      <td>1070.00</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316458</td>\n",
       "      <td>1070.00</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>316458</td>\n",
       "      <td>99024.72</td>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  REG_ANS  ValorDespesas   Ano  Trimestre\n",
       "0  316458        1070.00  2025          1\n",
       "1  316458        1070.00  2025          1\n",
       "2  316458        1070.00  2025          1\n",
       "3  316458        1070.00  2025          1\n",
       "4  316458       99024.72  2025          1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pasta_origem = Path(\"downloads/2025/extraido\")\n",
    "a = processar_csvs(pasta_origem)\n",
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2748263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 2113924 entries, 0 to 2113923\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Dtype  \n",
      "---  ------         -----  \n",
      " 0   ValorDespesas  float64\n",
      " 1   Ano            int64  \n",
      " 2   Trimestre      int64  \n",
      " 3   CNPJ           float64\n",
      " 4   Razao_Social   str    \n",
      "dtypes: float64(2), int64(2), str(1)\n",
      "memory usage: 80.6 MB\n",
      "None\n",
      "ValorDespesas        0\n",
      "Ano                  0\n",
      "Trimestre            0\n",
      "CNPJ             18739\n",
      "Razao_Social     18739\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "teste = pd.read_csv(f\"downloads/2025/extraido/consolidado/consolidado_despesas.csv\", encoding=\"utf-8\")\n",
    "print(teste.info())\n",
    "print(teste.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c045f79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
